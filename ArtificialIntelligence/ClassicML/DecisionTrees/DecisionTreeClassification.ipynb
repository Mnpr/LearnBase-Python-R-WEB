{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation( Python )\n",
    "\n",
    "***\n",
    "\n",
    "1. Classification\n",
    "2. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification\n",
    "\n",
    "### Tools & Libraries\n",
    "\n",
    "- **Pandas**( Data Analysis & Manipulation. )\n",
    "- **Numpy**( Numerical Multidimensional Array, Matrices and Computation. )\n",
    "- **Matplotlib**( Visualization )\n",
    "- **Scikit-Learn**( ML  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "***\n",
    "\n",
    "**Source :**\n",
    "*UCI ( banknote authentication ) Data Set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./Resources/bill_authentication.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information\n",
    "\n",
    "Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have $400x 400$ pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about $660 dpi$ were gained. Wavelet Transform tool were used to extract features from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape :\n",
      "(1372, 5)\n",
      "\n",
      "Head :\n",
      "   Variance  Skewness  Curtosis  Entropy  Class\n",
      "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
      "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
      "2   3.86600   -2.6383    1.9242  0.10645      0\n",
      "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
      "4   0.32924   -4.4552    4.5718 -0.98880      0\n"
     ]
    }
   ],
   "source": [
    "def data_info(daten):\n",
    "    print('Shape :')\n",
    "    print(daten.shape)\n",
    "    print('\\nHead :')\n",
    "    print(daten.head())\n",
    "\n",
    "data_info(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attributes :**\n",
    "- variance of Wavelet Transformed image (continuous)\n",
    "- skewness of Wavelet Transformed image (continuous)\n",
    "- curtosis of Wavelet Transformed image (continuous)\n",
    "- entropy of image (continuous)\n",
    "- class (integer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "***\n",
    "\n",
    "<u>**Attribute-Label Split.**</u>\n",
    "\n",
    "- Attribute set: $X$ with corresponding labels: $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('Class', axis=1) # Column except 'Class'\n",
    "y = dataset['Class'] # Column 'Class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Train-Test Split.**</u>\n",
    "\n",
    "- 20%( Test ) & 80%( Train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Shape :\n",
      "(1097, 4)\n",
      "\n",
      "Test Data Shape :\n",
      "(275, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "print('\\nTrain Data Shape :')\n",
    "print(X_train.shape)\n",
    "\n",
    "print('\\nTest Data Shape :')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "***\n",
    "\n",
    "- Scikit-Learn( tree Library )\n",
    "- DecisionTreeClassifier( Class )\n",
    "\n",
    "#### Training\n",
    "\n",
    "- fit Method( class Classifier )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "- predict Method( class Classifier )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "\n",
    "**Commonly used metrics :** confusion matrix, precision, recall & F1 score\n",
    "\n",
    "- Scikit-Learn( metrics Library )\n",
    "- confusion_matrix( evaluate Accuracy of a classification )\n",
    "- classification_report( Methods )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix :\n",
      "\n",
      "[[139   2]\n",
      " [  3 131]]\n",
      "\n",
      "\n",
      "Classification Report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       141\n",
      "           1       0.98      0.98      0.98       134\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       275\n",
      "   macro avg       0.98      0.98      0.98       275\n",
      "weighted avg       0.98      0.98      0.98       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('\\nConfusion Matrix :\\n')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\n\\nClassification Report :\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**confusion_matrix** $C$ such that $C_i,_j$ is equal to number of observation known to be in the group $i$ and predicted to be in group $j$. Thus in binary classification,the count of \n",
    "- $C_0,_0$ : true negatives, $tn$ : number of true negatives\n",
    "- $C_1,_0$ : false negatives, $fn$ \n",
    "- $C_1,_1$ : true positives, $tp$\n",
    "- $C_0,_1$ : false positives, $fb$\n",
    "\n",
    "**classification_report**( Precision, Recall, Fscore, Support ) for each Class.\n",
    "\n",
    "- <u>Precision</u> is the Ratio $\\frac{tp}{(tp+fp)}$. i.e. not to label negative sample as positive\n",
    "\n",
    "- <u>Recall</u> is the Ratio $\\frac{tp}{(tp+fn)}$ i.e. to find all the positive samples\n",
    "\n",
    "- <u>F-Score</u> is a weighted harmonic mean of the `precision` and `recall`\n",
    "    - `1`( Best value) : Recall and Precision are equally important.\n",
    "    - `0`( Worst value )\n",
    "- <u>Support</u> is the number of occurrences of each class in `y_true`.\n",
    "\n",
    "***\n",
    "\n",
    "|Total tested |Mis-Classified|\n",
    "| --- | --- |\n",
    "| 275 | 6 |\n",
    "| accuracy = 97.8% |\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
